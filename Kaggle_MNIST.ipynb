{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# COMP 551 Project 4 Kaggle MNIST\n",
    "\n",
    "### Ran Cheng, 260768706   |   XXXX, XXXXXXX    |    XXXX, XXXXXXX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# import data\n",
    "import numpy   as np \n",
    "import scipy.misc # to visualize only  \n",
    "x = np.loadtxt(\"./Data/train_x.csv\", delimiter=\",\") # load from text \n",
    "y = np.loadtxt(\"./Data/train_y.csv\", delimiter=\",\") \n",
    "x = x.reshape(-1, 64, 64) # reshape \n",
    "y = y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from skimage import measure\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.transform import resize\n",
    "\n",
    "def preProcessing(img):\n",
    "    #plt.imshow(img)\n",
    "    img[img < 255] = 0\n",
    "    img[img > 0] = 1\n",
    "    # Find contours at a constant value of 0.8\n",
    "    contours = measure.find_contours(img, 0.8)\n",
    "    # Find the biggest contour as candidate digital image\n",
    "    max_diff = -100\n",
    "    max_contor = None\n",
    "    for contor in contours:\n",
    "        x_diff = max(contor[:,1]) - min(contor[:,1])\n",
    "        y_diff = max(contor[:,0]) - min(contor[:,0])\n",
    "        # print('contour[ %d]'%i,  'x_diff: %0.2f' % x_diff, 'y_diff: %0.2f' % y_diff)\n",
    "        current_diff = max(x_diff, y_diff)\n",
    "        if current_diff > max_diff:\n",
    "            max_contor = contor\n",
    "            max_diff = current_diff\n",
    "    # Display the image and plot all contours found\n",
    "    # fig, ax = plt.subplots()\n",
    "    # ax.imshow(img, interpolation='nearest', cmap=plt.cm.gray)\n",
    "    # ax.plot(max_contor[:, 1], max_contor[:, 0], linewidth=2)\n",
    "    if max_contor is None:\n",
    "        return resize(img, (16, 16), mode='wrap')\n",
    "    box_x_s = math.floor(min(max_contor[:,1]))\n",
    "    box_x_e = math.ceil(max(max_contor[:,1]))\n",
    "    box_y_s = math.floor(min(max_contor[:,0]))\n",
    "    box_y_e = math.ceil(max(max_contor[:,0]))\n",
    "    img = img[box_y_s:box_y_e, box_x_s:box_x_e]\n",
    "    img = resize(img, (16, 16), mode='wrap')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "\n",
    "# jobs = []\n",
    "# for i in range(len(x)):\n",
    "#     p = multiprocessing.Process(target=preProcessing, args=(x[i],))\n",
    "#     jobs.append(p)\n",
    "#     p.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw = []\n",
    "for i in range(len(x)):\n",
    "    X_train_raw.append(preProcessing(x[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data to train and test\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train_raw, y, test_size=0.15, random_state=42)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvFvnyVgAAEBZJREFUeJzt3X2wVPV9x/H3R+CKoCIUNQpMAcf4EG2VEjWasVaqojKSTDMZbE2IOmWMtdFOrJKxE22nM61NYpu2UQcfEm2oxho1jMUoMaadWkURQSGoIBpBUDA+oFh5kG//2ENmud6Lex65l9/nNXPn7u453/v7cnY/nN2ze/aniMDM0rPHrm7AzHYNh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5aogU0O1qXBMVhDc9dp0KACoxX75GJs3lKozqwv+ICNbI5N6mTdRsM/WEM5Yc8zc9cNOOjA/IN9uC1/DbB11epCdWZ9wfx4uON1/bTfLFGlwi9psqTnJa2QNLOqpsysfoXDL2kA8D3gTOBI4FxJR1bVmJnVq8ye/zhgRUSsjIjNwJ3A1GraMrO6lQn/KGBV2/XV2W1m1g+UOdrf09sJH3l/TdIMYAbAYIaUGM7MqlRmz78aGNN2fTSwpvtKETErIiZGxMRBGlxiODOrUpnwPwkcKmmcpC5gGjCnmrbMrG6Fn/ZHxFZJlwAPAgOAWyNiaWWdmVmtSn3CLyLmAnMr6sXMGuRP+JklyuE3S1SjJ/bEPnux6cSjc9c98v2bc9cs3fx/uWsALp9yfu6abUueKzSW2a7kPb9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEtXoiT1N+lTXXoXqXjxveO6acZ6xYJfSwPwP4/enTCg01l73PVGori/ynt8sUQ6/WaIcfrNElZmua4ykRyQtk7RU0qVVNmZm9SpzwG8r8PWIWChpH+ApSfMi4pcV9WZmNSq854+ItRGxMLv8LrAMT9dl1m9U8ppf0ljgWGB+D8tmSFogacGWzRurGM7MKlA6/JL2Bn4MXBYRG7ov32G6rq6hZYczs4qUCr+kQbSCPzsi7qmmJTNrQpmj/QJuAZZFxHXVtWRmTSiz5z8J+BJwqqRF2c9ZFfVlZjUrM1Hn/wCqsBcza5A/4WeWqN32rL6iLjz7Z7lrHrl6RKGxYtOmQnX9wQs3fTp3zd7PDyo01tBT1+Wu+dLYBwqN9Z+PHl6o7sP16wvV1cl7frNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslShHR2GDDBoyME4ZMyV2n+4flrpl72NzcNUWdeehJheq2bdx9v9PwrtWP5a5Zs7XYY/GIriGF6oq4fcPIQnWzDx9dcSc9mx8PsyHe7OhUe+/5zRLl8JslyuE3S1QVX909QNLTku6voiEza0YVe/5Lac3WY2b9SNnv7R8NnA3cXE07ZtaUsnv+fwKuALZV0IuZNajMpB1TgHUR8dTHrPebufo2xwdFhzOzipWdtOMcSS8Dd9KavOOH3Vdqn6uvS4NLDGdmVSozRfc3ImJ0RIwFpgE/j4jzKuvMzGrl9/nNElXJpB0R8QvgF1X8LTNrhvf8ZolqdLqu2Lat0Jlsb7w3qoZuqvPA8kcL1Z1x8DEVd1I97blnobphe+yVv6ar0FCN+vK+bxSqu37uKblrhp39Yv6BcpwY6T2/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLl8JslqtGz+op666Xh+Yt+r/o+qrbHUYcXqtu25LncNQP237/QWJ/86VuF6oq46738czICzH/3kNw1pw77ZaGxzh5S7HsoHz/m7tw1R3/94tw1W27vfI5E7/nNEuXwmyWq7KQd+0m6W9JzkpZJ+kxVjZlZvcq+5v8u8NOI+IKkLqC5idLNrJTC4Ze0L3Ay8BWAiNgMbK6mLTOrW5mn/eOB9cD3s1l6b5Y0tKK+zKxmZcI/EJgA3BARxwIbgZndV2qfrmsLm0oMZ2ZVKhP+1cDqiJifXb+b1n8GO2ifrmsQxb4J1syqV2a6rteAVZIOy26aBBT75ISZNa7s0f4/B2ZnR/pXAueXb8nMmlAq/BGxCJhYUS9m1iB/ws8sUYrIMb9PSftqRByvSY2M9eCaRY2MU8afrjqpUN2r5+R/R/XtPxhfaKz/ve7GQnVFHPvktEJ1B0zNf6LTS39X7MOoL0y/oVBdU447YxULFn+gTtb1nt8sUQ6/WaIcfrNEOfxmiXL4zRLl8JslyuE3S5TDb5Yoh98sUQ6/WaIcfrNEOfxmiXL4zRLVL6brKuKTP/hqoboXvtLcWVs3jXm0UN2nb/li7pr9h75SaCzbdcbNmZG75rW3v9vxut7zmyXK4TdLVNnpuv5C0lJJSyTdIWlwVY2ZWb0Kh1/SKOBrwMSIOAoYABT7KhYza1zZp/0Dgb0kDaQ1T9+a8i2ZWRPKfG//q8C3gVeAtcA7EfFQVY2ZWb3KPO0fDkwFxgEHA0MlndfDep6uy6wPKvO0/w+BlyJifURsAe4BTuy+kqfrMuubyoT/FeAESUMkidZ0XcuqacvM6lbmNf98WpNzLgSezf7WrIr6MrOalZ2u62rg6op6MbMG+RN+Zoly+M0Stdue1Tf+rxcWqjv6iD/OXfPs8f9eaKyinpxwV6PjFXHfxr1z1xz8tY2FxtpaqKrvG3tf/nk033y783W95zdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9ZonbbE3tiU7HvCxz1xRW5a95a+X6hsYYPGFKorj9Yt3Xf3DVbf7Wqhk6sN97zmyXK4TdL1MeGX9KtktZJWtJ22whJ8yQtz34Pr7dNM6taJ3v+HwCTu902E3g4Ig4FHs6um1k/8rHhj4j/Bt7sdvNU4Lbs8m3A5yruy8xqVvQ1/4ERsRYg+31AdS2ZWRNqf6tP0gxgBsBgdt+3tsz6m6J7/tclHQSQ/V7X24qersusbyoa/jnA9OzydOAn1bRjZk3p5K2+O4DHgMMkrZZ0IfD3wGmSlgOnZdfNrB/52Nf8EXFuL4smVdyLmTXIn/AzS5TDb5ao3fasvqJiy+bcNdPGnFhorG+uLDal2EmD/X/2DqTcJVtG7q6TfHXOjyKzRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFEOv1miHH6zRDn8Zoly+M0S5fCbJcon9uxCV1z51UJ1P/z2d3LXjBu0d6Gxijqk6/XcNesvmlporG1d+U/seens6wuNtTvxnt8sUQ6/WaIcfrNEFZ2r71uSnpP0jKR7Je1Xb5tmVrWic/XNA46KiN8BXgC+UXFfZlazQnP1RcRDEbH9e5AeB0bX0JuZ1aiK1/wXAA/0tlDSDEkLJC3YwqYKhjOzKpQKv6SrgK3A7N7W8XRdZn1T4Q/5SJoOTAEmRURU15KZNaFQ+CVNBq4Efj8i3q+2JTNrQtG5+v4V2AeYJ2mRpBtr7tPMKlZ0rr5baujFzBrkT/iZJUpNHqvbVyPieHly37L+aNm63DUzhq2poRPr1LW/PjR3zX99/qjcNY+9cjvvfPBaR6c5es9vliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJ8lx9/dDsv5ySu2bGrFk1dGKd+tnFn81ds8eKp3PXRGzu/O/n/utmtltw+M0SVWi6rrZll0sKSSPrac/M6lJ0ui4kjQFOA16puCcza0Ch6boy/whcAfg7+836oUKv+SWdA7waEYs7WNfTdZn1Qbnf6pM0BLgKOL2T9SNiFjALWl/gmXc8M6tHkT3/IcA4YLGkl2nN0LtQ0ieqbMzM6pV7zx8RzwIHbL+e/QcwMSLeqLAvM6tZ0em6zKyfKzpdV/vysZV1Y2aN8Sf8zBLlE3v6ocH3P5G75ti/vbiGTnr39F9d3+h4eY2fd0GhuiOu+XWhuj1eyn+STt285zdLlMNvliiH3yxRDr9Zohx+s0Q5/GaJcvjNEuXwmyXK4TdLlMNvliiH3yxRDr9Zohx+s0Qpormv1ZO0HvhVL4tHAn3h24Dcx47cx476eh+/HRH7d/IHGg3/zkhaEBET3Yf7cB/N9OGn/WaJcvjNEtWXwt9X5pB2HztyHzvabfroM6/5zaxZfWnPb2YNajT8kiZLel7SCkkze1i+p6QfZcvnSxpbQw9jJD0iaZmkpZIu7WGdUyS9I2lR9vPNqvtoG+tlSc9m4yzoYbkk/XO2TZ6RNKHi8Q9r+3cukrRB0mXd1qlte/Q0BbykEZLmSVqe/R7eS+30bJ3lkqbX0Me3JD2Xbfd7Je3XS+1O78MK+rhG0qtt2/+sXmp3mq+PiIhGfoABwIvAeKALWAwc2W2di4Ebs8vTgB/V0MdBwITs8j7ACz30cQpwf0Pb5WVg5E6WnwU8AAg4AZhf8330Gq33ihvZHsDJwARgSdtt/wDMzC7PBK7toW4EsDL7PTy7PLziPk4HBmaXr+2pj07uwwr6uAa4vIP7bqf56v7T5J7/OGBFRKyMiM3AncDUbutMBW7LLt8NTJKkKpuIiLURsTC7/C6wDBhV5RgVmwrcHi2PA/tJOqimsSYBL0ZEbx/Eqlz0PAV8++PgNuBzPZSeAcyLiDcj4i1gHjC5yj4i4qGI2JpdfZzWvJS16mV7dKKTfO2gyfCPAla1XV/NR0P3m3Wyjf4O8Ft1NZS9rDgWmN/D4s9IWizpAUmfqqsHIICHJD0laUYPyzvZblWZBtzRy7KmtgfAgRGxFlr/WdM2N2SbJrcLwAW0noH15OPuwypckr38uLWXl0G5t0eT4e9pD979rYZO1qmEpL2BHwOXRcSGbosX0nrq+7vAvwD31dFD5qSImACcCfyZpJO7t9pDTeXbRFIXcA7wHz0sbnJ7dKrJx8pVwFZgdi+rfNx9WNYNtGbHPgZYC3ynpzZ7uG2n26PJ8K8GxrRdHw2s6W0dSQOBYRR7CrRTkgbRCv7siLin+/KI2BAR72WX5wKDJI2suo/s76/Jfq8D7qX19K1dJ9utCmcCCyPi9R56bGx7ZF7f/tIm+72uh3Ua2S7ZgcQpwJ9E9uK6uw7uw1Ii4vWI+DAitgE39fL3c2+PJsP/JHCopHHZXmYaMKfbOnOA7UdtvwD8vLcNXlR2DOEWYFlEXNfLOp/YfqxB0nG0tlOxeZp23stQSftsv0zrANOSbqvNAb6cHfU/AXhn+1Piip1LL0/5m9oebdofB9OBn/SwzoPA6ZKGZ0+DT89uq4ykycCVwDkR8X4v63RyH5bto/0Yz+d7+fud5GtHVRyhzHEk8yxaR9dfBK7KbvsbWhsXYDCtp50rgCeA8TX08FlaT4eeARZlP2cBFwEXZetcAiyldcT0ceDEmrbH+GyMxdl427dJey8Cvpdts2eBiTX0MYRWmIe13dbI9qD1H85aYAutvdeFtI7zPAwsz36PyNadCNzcVntB9lhZAZxfQx8raL2O3v442f5O1MHA3J3dhxX38W/Zff8MrUAf1L2P3vK1sx9/ws8sUf6En1miHH6zRDn8Zoly+M0S5fCbJcrhN0uUw2+WKIffLFH/DwQmdfz67YyWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[23])\n",
    "print(y_test[23])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Start With Baseline, Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets, svm, metrics\n",
    "\n",
    "############### Classification with grid search ##############\n",
    "# If you don't want to wait, comment this section and uncommnet section below with\n",
    "# standalone SVM classifier\n",
    "\n",
    "# Create parameters grid for RBF kernel, we have to set C and gamma\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# generate matrix with all gammas\n",
    "# [ [10^-4, 2*10^-4, 5*10^-4], \n",
    "#   [10^-3, 2*10^-3, 5*10^-3],\n",
    "#   ......\n",
    "#   [10^3, 2*10^3, 5*10^3] ]\n",
    "#gamma_range = np.outer(np.logspace(-4, 3, 8),np.array([1,2, 5]))\n",
    "gamma_range = np.outer(np.logspace(-3, 0, 4),np.array([1,5]))\n",
    "gamma_range = gamma_range.flatten()\n",
    "\n",
    "# generate matrix with all C\n",
    "#C_range = np.outer(np.logspace(-3, 3, 7),np.array([1,2, 5]))\n",
    "C_range = np.outer(np.logspace(-1, 1, 3),np.array([1,5]))\n",
    "# flatten matrix, change to 1D numpy array\n",
    "C_range = C_range.flatten()\n",
    "\n",
    "parameters = {'kernel':['rbf'], 'C':C_range, 'gamma': gamma_range}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape X data to 2d for linear fitting\n",
    "X_train = np.asarray(X_train)\n",
    "nsamples, nx, ny = X_train.shape\n",
    "X_train = X_train.reshape((nsamples,nx*ny))\n",
    "X_test = np.asarray(X_test)\n",
    "nsamples, nx, ny = X_test.shape\n",
    "X_test = X_test.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "class MidpointNormalize(Normalize):\n",
    "\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        x, y = [self.vmin, self.midpoint, self.vmax], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "def plot_param_space_scores(scores, C_range, gamma_range):\n",
    "    \"\"\"\n",
    "    Draw heatmap of the validation accuracy as a function of gamma and C\n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    scores - 2D numpy array with accuracies\n",
    "    \n",
    "    \"\"\"\n",
    "    #\n",
    "    # The score are encoded as colors with the hot colormap which varies from dark\n",
    "    # red to bright yellow. As the most interesting scores are all located in the\n",
    "    # 0.92 to 0.97 range we use a custom normalizer to set the mid-point to 0.92 so\n",
    "    # as to make it easier to visualize the small variations of score values in the\n",
    "    # interesting range while not brutally collapsing all the low score values to\n",
    "    # the same color.\n",
    "\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.subplots_adjust(left=.2, right=0.95, bottom=0.15, top=0.95)\n",
    "    plt.imshow(scores, interpolation='nearest', cmap=plt.cm.jet,\n",
    "               norm=MidpointNormalize(vmin=0.5, midpoint=0.9))\n",
    "    plt.xlabel('gamma')\n",
    "    plt.ylabel('C')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(np.arange(len(gamma_range)), gamma_range, rotation=45)\n",
    "    plt.yticks(np.arange(len(C_range)), C_range)\n",
    "    plt.title('Validation accuracy')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start param searching at 2018-03-09 01:31:50.882396\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "[CV] gamma=0.001, C=0.1, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=0.1, kernel=rbf, total= 9.7min\n",
      "[CV] gamma=0.001, C=0.1, kernel=rbf ..................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed: 14.2min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... gamma=0.001, C=0.1, kernel=rbf, total= 8.4min\n",
      "[CV] gamma=0.001, C=0.1, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=0.1, kernel=rbf, total= 8.4min\n",
      "[CV] gamma=0.005, C=0.1, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.1, kernel=rbf, total= 5.4min\n",
      "[CV] gamma=0.005, C=0.1, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.1, kernel=rbf, total= 5.4min\n",
      "[CV] gamma=0.005, C=0.1, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.1, kernel=rbf, total= 5.4min\n",
      "[CV] gamma=0.01, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.1, kernel=rbf, total= 4.6min\n",
      "[CV] gamma=0.01, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.1, kernel=rbf, total= 4.6min\n",
      "[CV] gamma=0.01, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.1, kernel=rbf, total= 4.6min\n",
      "[CV] gamma=0.05, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.1, kernel=rbf, total= 5.1min\n",
      "[CV] gamma=0.05, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.1, kernel=rbf, total= 5.2min\n",
      "[CV] gamma=0.05, C=0.1, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.1, kernel=rbf, total= 5.2min\n",
      "[CV] gamma=0.1, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.1, kernel=rbf, total= 9.1min\n",
      "[CV] gamma=0.1, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.1, kernel=rbf, total= 9.2min\n",
      "[CV] gamma=0.1, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.1, kernel=rbf, total= 9.2min\n",
      "[CV] gamma=0.5, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.1, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.1, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.1, kernel=rbf, total=13.4min\n",
      "[CV] gamma=1.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.1, kernel=rbf, total=13.5min\n",
      "[CV] gamma=1.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.1, kernel=rbf, total=13.5min\n",
      "[CV] gamma=1.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.1, kernel=rbf, total=13.5min\n",
      "[CV] gamma=5.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.1, kernel=rbf, total=13.4min\n",
      "[CV] gamma=5.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.1, kernel=rbf, total=13.4min\n",
      "[CV] gamma=5.0, C=0.1, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.1, kernel=rbf, total=13.4min\n",
      "[CV] gamma=0.001, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=0.5, kernel=rbf, total= 5.2min\n",
      "[CV] gamma=0.001, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=0.5, kernel=rbf, total= 5.3min\n",
      "[CV] gamma=0.001, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=0.5, kernel=rbf, total= 5.3min\n",
      "[CV] gamma=0.005, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.5, kernel=rbf, total= 3.5min\n",
      "[CV] gamma=0.005, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.5, kernel=rbf, total= 3.6min\n",
      "[CV] gamma=0.005, C=0.5, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=0.5, kernel=rbf, total= 3.6min\n",
      "[CV] gamma=0.01, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.5, kernel=rbf, total= 3.0min\n",
      "[CV] gamma=0.01, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.5, kernel=rbf, total= 3.1min\n",
      "[CV] gamma=0.01, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=0.5, kernel=rbf, total= 3.0min\n",
      "[CV] gamma=0.05, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.5, kernel=rbf, total= 3.6min\n",
      "[CV] gamma=0.05, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.5, kernel=rbf, total= 3.7min\n",
      "[CV] gamma=0.05, C=0.5, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=0.5, kernel=rbf, total= 3.6min\n",
      "[CV] gamma=0.1, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.5, kernel=rbf, total= 7.0min\n",
      "[CV] gamma=0.1, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.5, kernel=rbf, total= 7.1min\n",
      "[CV] gamma=0.1, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=0.5, kernel=rbf, total= 7.1min\n",
      "[CV] gamma=0.5, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=1.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=1.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=1.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=5.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=5.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.5, kernel=rbf, total=13.5min\n",
      "[CV] gamma=5.0, C=0.5, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=0.5, kernel=rbf, total=14.3min\n",
      "[CV] gamma=0.001, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=1.0, kernel=rbf, total= 4.4min\n",
      "[CV] gamma=0.001, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=1.0, kernel=rbf, total= 4.5min\n",
      "[CV] gamma=0.001, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=1.0, kernel=rbf, total= 4.4min\n",
      "[CV] gamma=0.005, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=1.0, kernel=rbf, total= 3.0min\n",
      "[CV] gamma=0.005, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=1.0, kernel=rbf, total= 3.1min\n",
      "[CV] gamma=0.005, C=1.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=1.0, kernel=rbf, total= 3.1min\n",
      "[CV] gamma=0.01, C=1.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=1.0, kernel=rbf, total= 2.6min\n",
      "[CV] gamma=0.01, C=1.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=1.0, kernel=rbf, total= 2.7min\n",
      "[CV] gamma=0.01, C=1.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=1.0, kernel=rbf, total= 2.7min\n",
      "[CV] gamma=0.05, C=1.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=1.0, kernel=rbf, total= 3.6min\n",
      "[CV] gamma=0.05, C=1.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=1.0, kernel=rbf, total= 3.9min\n",
      "[CV] gamma=0.05, C=1.0, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... gamma=0.05, C=1.0, kernel=rbf, total= 3.7min\n",
      "[CV] gamma=0.1, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=1.0, kernel=rbf, total= 8.0min\n",
      "[CV] gamma=0.1, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=1.0, kernel=rbf, total= 8.0min\n",
      "[CV] gamma=0.1, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=1.0, kernel=rbf, total= 8.1min\n",
      "[CV] gamma=0.5, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=1.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=0.5, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=1.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=0.5, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=1.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=1.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=1.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=1.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=1.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=1.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=1.0, kernel=rbf, total=14.1min\n",
      "[CV] gamma=5.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=1.0, kernel=rbf, total=14.2min\n",
      "[CV] gamma=5.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=1.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=5.0, C=1.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=1.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=0.001, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=5.0, kernel=rbf, total= 3.3min\n",
      "[CV] gamma=0.001, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=5.0, kernel=rbf, total= 3.3min\n",
      "[CV] gamma=0.001, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.001, C=5.0, kernel=rbf, total= 3.3min\n",
      "[CV] gamma=0.005, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=5.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.005, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=5.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.005, C=5.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.005, C=5.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.01, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=5.0, kernel=rbf, total= 2.3min\n",
      "[CV] gamma=0.01, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=5.0, kernel=rbf, total= 2.3min\n",
      "[CV] gamma=0.01, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.01, C=5.0, kernel=rbf, total= 2.3min\n",
      "[CV] gamma=0.05, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=5.0, kernel=rbf, total= 4.0min\n",
      "[CV] gamma=0.05, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=5.0, kernel=rbf, total= 4.0min\n",
      "[CV] gamma=0.05, C=5.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.05, C=5.0, kernel=rbf, total= 4.0min\n",
      "[CV] gamma=0.1, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=5.0, kernel=rbf, total= 8.3min\n",
      "[CV] gamma=0.1, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=5.0, kernel=rbf, total= 8.3min\n",
      "[CV] gamma=0.1, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.1, C=5.0, kernel=rbf, total= 8.3min\n",
      "[CV] gamma=0.5, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=5.0, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=5.0, kernel=rbf, total=13.5min\n",
      "[CV] gamma=0.5, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=0.5, C=5.0, kernel=rbf, total=13.6min\n",
      "[CV] gamma=1.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=5.0, kernel=rbf, total=13.9min\n",
      "[CV] gamma=1.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=5.0, kernel=rbf, total=13.9min\n",
      "[CV] gamma=1.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=1.0, C=5.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=5.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=5.0, kernel=rbf, total=14.0min\n",
      "[CV] gamma=5.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=5.0, kernel=rbf, total=13.9min\n",
      "[CV] gamma=5.0, C=5.0, kernel=rbf ....................................\n",
      "[CV] ..................... gamma=5.0, C=5.0, kernel=rbf, total=14.8min\n",
      "[CV] gamma=0.001, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=10.0, kernel=rbf, total= 3.2min\n",
      "[CV] gamma=0.001, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=10.0, kernel=rbf, total= 3.2min\n",
      "[CV] gamma=0.001, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=10.0, kernel=rbf, total= 3.2min\n",
      "[CV] gamma=0.005, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=10.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.005, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=10.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.005, C=10.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=10.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.01, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=10.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.01, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=10.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.01, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=10.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.05, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=10.0, kernel=rbf, total= 4.4min\n",
      "[CV] gamma=0.05, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=10.0, kernel=rbf, total= 4.4min\n",
      "[CV] gamma=0.05, C=10.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=10.0, kernel=rbf, total= 4.3min\n",
      "[CV] gamma=0.1, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=10.0, kernel=rbf, total= 9.0min\n",
      "[CV] gamma=0.1, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=10.0, kernel=rbf, total= 9.5min\n",
      "[CV] gamma=0.1, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=10.0, kernel=rbf, total= 9.2min\n",
      "[CV] gamma=0.5, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=10.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=0.5, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=10.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=0.5, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=10.0, kernel=rbf, total=13.6min\n",
      "[CV] gamma=1.0, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=10.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=1.0, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=10.0, kernel=rbf, total=13.6min\n",
      "[CV] gamma=1.0, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=10.0, kernel=rbf, total=13.6min\n",
      "[CV] gamma=5.0, C=10.0, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... gamma=5.0, C=10.0, kernel=rbf, total=13.6min\n",
      "[CV] gamma=5.0, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=5.0, C=10.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=5.0, C=10.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=5.0, C=10.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=0.001, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=50.0, kernel=rbf, total= 2.6min\n",
      "[CV] gamma=0.001, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=50.0, kernel=rbf, total= 2.6min\n",
      "[CV] gamma=0.001, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.001, C=50.0, kernel=rbf, total= 2.6min\n",
      "[CV] gamma=0.005, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=50.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.005, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=50.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.005, C=50.0, kernel=rbf .................................\n",
      "[CV] .................. gamma=0.005, C=50.0, kernel=rbf, total= 2.4min\n",
      "[CV] gamma=0.01, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=50.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.01, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=50.0, kernel=rbf, total= 2.5min\n",
      "[CV] gamma=0.01, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.01, C=50.0, kernel=rbf, total= 2.6min\n",
      "[CV] gamma=0.05, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=50.0, kernel=rbf, total= 4.0min\n",
      "[CV] gamma=0.05, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=50.0, kernel=rbf, total= 4.1min\n",
      "[CV] gamma=0.05, C=50.0, kernel=rbf ..................................\n",
      "[CV] ................... gamma=0.05, C=50.0, kernel=rbf, total= 4.1min\n",
      "[CV] gamma=0.1, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=50.0, kernel=rbf, total= 8.4min\n",
      "[CV] gamma=0.1, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=50.0, kernel=rbf, total= 8.4min\n",
      "[CV] gamma=0.1, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.1, C=50.0, kernel=rbf, total= 8.4min\n",
      "[CV] gamma=0.5, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=50.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=0.5, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=50.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=0.5, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=0.5, C=50.0, kernel=rbf, total=13.7min\n",
      "[CV] gamma=1.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=50.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=1.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=50.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=1.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=1.0, C=50.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=5.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=5.0, C=50.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=5.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=5.0, C=50.0, kernel=rbf, total=13.8min\n",
      "[CV] gamma=5.0, C=50.0, kernel=rbf ...................................\n",
      "[CV] .................... gamma=5.0, C=50.0, kernel=rbf, total=13.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 144 out of 144 | elapsed: 1677.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time, param searching 1 day, 4:02:38.595454\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'MidpointNormalize' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-030f2b5e7fd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m                                                      len(gamma_range))\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mplot_param_space_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_range\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-452f45c2d454>\u001b[0m in \u001b[0;36mplot_param_space_scores\u001b[0;34m(scores, C_range, gamma_range)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots_adjust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbottom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     plt.imshow(scores, interpolation='nearest', cmap=plt.cm.jet,\n\u001b[0;32m---> 23\u001b[0;31m                norm=MidpointNormalize(vmin=0.5, midpoint=0.9))\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gamma'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MidpointNormalize' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0878d9748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "svm_clsf = svm.SVC()\n",
    "grid_clsf = GridSearchCV(estimator=svm_clsf,param_grid=parameters,n_jobs=1, verbose=2)\n",
    "\n",
    "\n",
    "start_time = dt.datetime.now()\n",
    "print('Start param searching at {}'.format(str(start_time)))\n",
    "\n",
    "grid_clsf.fit(X_train, y_train)\n",
    "\n",
    "elapsed_time= dt.datetime.now() - start_time\n",
    "print('Elapsed time, param searching {}'.format(str(elapsed_time)))\n",
    "sorted(grid_clsf.cv_results_.keys())\n",
    "\n",
    "classifier = grid_clsf.best_estimator_\n",
    "params = grid_clsf.best_params_\n",
    "\n",
    "\n",
    "\n",
    "scores = grid_clsf.cv_results_['mean_test_score'].reshape(len(C_range),\n",
    "                                                     len(gamma_range))\n",
    "\n",
    "plot_param_space_scores(scores, C_range, gamma_range)\n",
    "\n",
    "\n",
    "######################### end grid section #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe0878f1128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plot_param_space_scores(scores, C_range, gamma_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start learning at 2018-03-09 00:56:52.907149\n",
      "Stop learning 2018-03-09 01:04:23.296147\n",
      "Elapsed learning 0:07:30.388998\n"
     ]
    }
   ],
   "source": [
    "################ Classifier with good params ###########\n",
    "# Create a classifier: a support vector classifier\n",
    "from sklearn import datasets, svm, metrics\n",
    "param_C = 5\n",
    "param_gamma = 0.05\n",
    "classifier = svm.SVC(C=param_C,gamma=param_gamma)\n",
    "\n",
    "# We learn the digits on train part\n",
    "start_time = dt.datetime.now()\n",
    "print('Start learning at {}'.format(str(start_time)))\n",
    "classifier.fit(X_train, y_train)\n",
    "end_time = dt.datetime.now() \n",
    "print('Stop learning {}'.format(str(end_time)))\n",
    "elapsed_time= end_time - start_time\n",
    "print('Elapsed learning {}'.format(str(elapsed_time)))\n",
    "\n",
    "########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.062\n",
      "F1 Score: 0.939\n"
     ]
    }
   ],
   "source": [
    "mse_test = metrics.mean_squared_error(y_test, predict_y)\n",
    "f1_test = metrics.f1_score(y_test, predict_y,average='macro')\n",
    "print('MSE: %0.3f' %mse_test)\n",
    "print('F1 Score: %0.3f' %f1_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 Feed Forward NN with BP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the progress meter widget\n",
    "from tqdm import tqdm\n",
    "import numpy \n",
    "import math\n",
    "import scipy.special\n",
    "\n",
    "# define the Feed Forward NN:\n",
    "class NeuralNetwork:\n",
    "    # initialization\n",
    "    # dims -> dimenison of the neural network architecture: [64*64 100 10] This is one hidden layer with 100 HU.\n",
    "    # alpha -> learning rate\n",
    "    # decay -> l1 weight decay\n",
    "    # activation_func -> activation function //!!! maybe better to use LeRU for each layer ****TODO******\n",
    "    # activation_func_prime -> differential activation function\n",
    "    def __init__(self, dims, alpha, decay, activation_func, activation_func_prime):\n",
    "        self.layers = [] # contain all layers of neurons.\n",
    "        # hidden layer:\n",
    "        for i in range(1, len(dims)):\n",
    "            # hidden layer weight list for each hidden layer\n",
    "            hiddenlayer_weights = []\n",
    "            # for each layer, and each neuron, they contains the last layer's weight combination\n",
    "            # the number of weight that the current neuron pocessessed is equal to the last layer's number:\n",
    "            for j in range(dims[i]):\n",
    "                # unifying the weight distribution between [-1,1]\n",
    "                hiddenlayer_weights.append(numpy.random.uniform(-1, 1, dims[i - 1]))\n",
    "            hiddenlayer_weights = numpy.array(hiddenlayer_weights)\n",
    "            self.layers.append((hiddenlayer_weights))\n",
    "        self.alpha = alpha\n",
    "        self.weight_decay = decay\n",
    "        self.f = activation_func\n",
    "        self.f_prime = activation_func_prime\n",
    "        \n",
    "    # feed forward\n",
    "    def feedForward(self, inputs):\n",
    "        # loop through the layers and produce the output from the production of last layer\n",
    "        # inputs and the current neurons' weight lists\n",
    "        layer_outputs = []\n",
    "        # loop layers of weights:\n",
    "        for i in range(len(self.layers)):\n",
    "            if i == 0:\n",
    "                # first layer should be the input layer\n",
    "                current_output = self.f(numpy.dot(self.layers[i], inputs))\n",
    "            else:\n",
    "                # other layer's input should be the last layer's output\n",
    "                current_output = self.f(numpy.dot(self.layers[i], layer_outputs[i-1]))\n",
    "            current_output = numpy.array(current_output)\n",
    "            layer_outputs.append(current_output)\n",
    "        return layer_outputs\n",
    "        \n",
    "    # back propogation\n",
    "    def backPropagation(self, inputs, targets):\n",
    "        # implement the BP:\n",
    "        # for each layer we adjust the weight list according to the error function\n",
    "        # conversion of inputs and target arrays to transposed numpy matrixes\n",
    "        inputs = numpy.transpose(numpy.array([numpy.array(inputs)]))\n",
    "        targets = numpy.transpose(numpy.array([numpy.array(targets)]))\n",
    "        # outputs of each layer, we need all the layer's data to perform BP\n",
    "        outputs = self.feedForward(inputs)\n",
    "        # get error from the last layer output and target\n",
    "        outErr = targets - outputs[len(outputs) - 1]\n",
    "        # initialize hidden layer errors for each HU\n",
    "        HiddenErrs = [None] * (len(outputs) - 1)\n",
    "        # loop backward to update the previous layer's error\n",
    "        for i in reversed(range(len(outputs) - 1)):\n",
    "            HiddenErr = 0\n",
    "            if i == len(outputs) - 2:\n",
    "                # from the output error\n",
    "                hiddenErr = numpy.dot(numpy.transpose(self.layers[i + 1]), outErr)\n",
    "            else:\n",
    "                # from 'back' layer\n",
    "                hiddenErr = numpy.dot(numpy.transpose(self.layers[i + 1]), hiddenErrs[i + 1])\n",
    "            HiddenErrs[i] = hiddenErr\n",
    "        # update the weights using l1 weight decay\n",
    "        for i in reversed(range(len(self.layers))):\n",
    "            if i == len(self.layers) - 1:\n",
    "                self.layers[i] += (self.alpha * numpy.dot((outErr * self.f_prime(outputs[i])), numpy.transpose(outputs[i - 1]))) + (self.alpha * self.weight_decay * self.layers[i])\n",
    "            elif i == 0:\n",
    "                self.layers[i] += (self.alpha * numpy.dot((HiddenErrs[i] * self.f_prime(outputs[i])), numpy.transpose(inputs))) + (self.alpha * self.weight_decay * self.layers[i])\n",
    "            else:\n",
    "                self.layers[i] += (self.alpha * numpy.dot((HiddenErrs[i] * self.f_prime(outputs[i])), numpy.transpose(outputs[i - 1]))) + (self.alpha * self.weight_decay * self.layers[i])\n",
    "\n",
    "    # train\n",
    "    def train(self, inputs, targets):\n",
    "        self.backPropagation(inputs, targets)\n",
    "        \n",
    "    def query(self, inputs):\n",
    "        inputs = numpy.transpose(numpy.array([numpy.array(inputs)]))\n",
    "        return self.feedForward(inputs)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [00:15<00:00, 6601.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5]]\n",
      "[[1.]]\n",
      "[[1.22776583e-159]]\n",
      "[[3.50394896e-80]]\n"
     ]
    }
   ],
   "source": [
    "# test of the neural network\n",
    "nn = NeuralNetwork([2, 2, 1], 0.01, 0.001, lambda x: scipy.special.expit(x), lambda x: x * (1 - x))\n",
    "for i in tqdm(range(100000)):\n",
    "    nn.train([0, 0], [0])\n",
    "    nn.train([0, 1], [0])\n",
    "    nn.train([1, 1], [1])\n",
    "    nn.train([1, 0], [0])\n",
    "    nn.train([1, 1], [1])\n",
    "\n",
    "print(nn.query([0, 1]))\n",
    "print(nn.query([1, 1]))\n",
    "print(nn.query([1, 0]))\n",
    "print(nn.query([0, 0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the encoding from the label, translate digits into binary vectors.\n",
    "def encodingLabel(num):\n",
    "    encode = []\n",
    "    # init with 0s\n",
    "    for i in range(10):\n",
    "        encode.append(0)\n",
    "    encode[num] = 1\n",
    "    return encode\n",
    "def encodeLabelWrapper(labels):\n",
    "    for i in range(len(labels)):\n",
    "        if i == 0:\n",
    "            print(type(labels[i]))\n",
    "        labels[i] = encodingLabel(labels[i])\n",
    "    return labels\n",
    "def kFoldsPreperation(images_train, labels_train):\n",
    "    dataPerFold = int(len(images_train) / 10)\n",
    "\n",
    "    imageFolds = []\n",
    "\n",
    "    labelFolds = []\n",
    "\n",
    "    iFold = []\n",
    "    lFold = []\n",
    "    for i in range(len(images_train)):\n",
    "        iFold.append(images_train[i])\n",
    "        lFold.append(labels_train[i])\n",
    "        # if i is a multiple of the datafold then we add the fold to the folds layer\n",
    "        # because only a number divisible by 5000 means it is a multiple of 5000\n",
    "        # like 5000 * 2, 5000 * 3, etc\n",
    "        # 0 mod anything is 0 so I check for that\n",
    "        if i != 0 and i % dataPerFold == 0:\n",
    "            # we append the fold to the folds arrays\n",
    "            imageFolds.append(iFold)\n",
    "            labelFolds.append(lFold)\n",
    "            # and we empty out the iFold and lFold array for new dataset to be filled\n",
    "            iFold = []\n",
    "            lFold = []\n",
    "\n",
    "    return (imageFolds, labelFolds)\n",
    "\n",
    "def train(nn, imageFolds, labelFolds):\n",
    "    # pick a random number, the index that gets tested that round won't be tested again ever\n",
    "    # and gets placed in an array of indexes that has already been tested\n",
    "    indexesTested = [] # contains the indexes from the folds array for which data has been tested\n",
    "\n",
    "    # will contain values 0 to imageFolds\n",
    "    pool = []\n",
    "    for i in range(len(imageFolds)):\n",
    "        pool.append(i)\n",
    "\n",
    "    # holds the array of all the percentages that were obtained while training\n",
    "    percentageList = []\n",
    "\n",
    "    # we loop till the indexesTested is not equal to 10\n",
    "    while len(indexesTested) != len(imageFolds):\n",
    "        # selects a random number from a pool of 0 to 9 values\n",
    "        poolIndex = random.randint(0, len(pool) - 1)\n",
    "        randomIndex = pool[poolIndex]\n",
    "        # after that specific value is picked from 0 to 9 we delete the value from pool so that it cannot be\n",
    "        # selected again\n",
    "        del pool[poolIndex]\n",
    "\n",
    "        print(\"Training on folds....\")\n",
    "        for i in range(len(imageFolds)):\n",
    "            # if i equals the randomIndex we skip the loop\n",
    "            if i == randomIndex:\n",
    "                continue\n",
    "            for j in tqdm(range(len(imageFolds[i]))):\n",
    "                nn.train(imageFolds[i][j], labelFolds[i][j])\n",
    "\n",
    "\n",
    "        # now we test the randomIndex selected from the k folds\n",
    "        print(\"Testing on a random fold at index {}....\".format(randomIndex))\n",
    "        accuracy = 0\n",
    "        for i in tqdm(range(len(imageFolds[randomIndex]))):\n",
    "            result = nn.query(imageFolds[randomIndex][i])\n",
    "            result = result.tolist()\n",
    "\n",
    "            if (result.index(max(result)) == labelFolds[randomIndex][i].index(max(labelFolds[randomIndex][i]))):\n",
    "                accuracy += 1\n",
    "\n",
    "        # at the end of the for loop we find the accuracy in percentage\n",
    "\n",
    "        percentageAccuracy = (accuracy / len(imageFolds[randomIndex])) * 100\n",
    "\n",
    "        print(\"Accuracy of Neural Network at the moment... {}%\".format(percentageAccuracy))\n",
    "\n",
    "        indexesTested.append(randomIndex)\n",
    "\n",
    "        percentageList.append(percentageAccuracy)\n",
    "\n",
    "    summation = 0\n",
    "    for i in range(len(percentageList)):\n",
    "        summation += percentageList[i]\n",
    "\n",
    "    mean = summation / len(percentageList)\n",
    "\n",
    "    print(\"Overall accuracy of the Neural Network is... {}%\".format(mean))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.0]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'int'>\n"
     ]
    }
   ],
   "source": [
    "# train Neural Networks:\n",
    "y = y.tolist()\n",
    "y = [int(i) for i in y]\n",
    "X_train_nn = [img.reshape(256,).tolist() for img in X_train_raw]\n",
    "label_train = encodeLabelWrapper(y)\n",
    "imageFolds, labelFolds = kFoldsPreperation(X_train_nn, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4287.79it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4430.59it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4452.49it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4424.75it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4445.89it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4433.70it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4459.79it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4426.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 8....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 19403.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 80.64%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4459.94it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4448.96it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4432.30it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4450.78it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4462.76it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4413.39it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4426.97it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4485.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 3....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 19858.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 80.78%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4388.78it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4468.56it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4421.67it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4425.70it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4466.78it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4445.35it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4395.28it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4423.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 7....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 19950.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.44%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4424.44it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4456.19it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4435.04it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4351.37it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4433.43it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4443.17it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4477.39it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4425.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 6....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 19815.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.10000000000001%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:01<00:00, 4419.08it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4381.73it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4411.62it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4441.33it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4369.65it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4452.17it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4361.93it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4438.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 0....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:00<00:00, 19641.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.22375524895021%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4405.91it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4411.86it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4404.14it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4481.14it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4427.14it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4455.30it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4461.55it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4416.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 5....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 20023.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.52000000000001%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4343.86it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4437.69it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4467.19it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4485.49it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4354.53it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4368.58it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4362.66it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4340.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 4....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 18676.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.62%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4410.91it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4374.12it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4344.02it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4371.63it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4269.45it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4259.66it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4306.25it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4399.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 1....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 19704.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 80.32000000000001%\n",
      "Training on folds....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 4281.25it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4334.47it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4361.57it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4231.53it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4257.29it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4229.25it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4162.99it/s]\n",
      "100%|██████████| 5000/5000 [00:01<00:00, 4144.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on a random fold at index 2....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [00:00<00:00, 20434.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Neural Network at the moment... 81.3%\n",
      "Overall accuracy of the Neural Network is... 81.10486169432781%\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "nn = NeuralNetwork([256, 200, 10], 0.01, 0.001, lambda x: scipy.special.expit(x), lambda x: x * (1 - x))\n",
    "train(nn, imageFolds, labelFolds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
